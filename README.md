
---

# ğŸš€ NGINX Deployment Scenarios â€” A Simple Hands-On Guide

This repo is a quick, practical walkthrough of how real deployments work using **Flask**, **Waitress**, and **NGINX**.  
Each scenario builds on the previous one â€” starting from a basic dev server and moving all the way to **HTTPS, virtual hosting, static file serving, and load balancing**.  
Perfect for understanding how modern web apps are actually deployed in the real world.

These scenarios have been given to us by our professor [Dr. Priyank Thakkar](https://www.kaggle.com/priyankdl)


ğŸ“„ **Full Documentation:**
ğŸ‘‰ [`Detailed_Steps.docx`](Detailed_Steps.docx)

---

# ğŸ“š Table of Contents

* [ğŸ¯ Aim of the Practical](#-aim-of-the-practical)
* [ğŸ“¦ Repository Structure](#-repository-structure)
* [ğŸ§  Concepts You Will Learn](#-concepts-you-will-learn)
* [ğŸš€ Scenarios Overview](#-scenarios-overview)
* [âš™ï¸ Setup & Usage Instructions](#ï¸-setup--usage-instructions)
* [ğŸ“ Scenario Descriptions](#-scenario-descriptions)
* [ğŸ³ Commands Reference](#-commands-reference)
* [ğŸ”’ SSL / HTTPS Notes](#-ssl--https-notes)
* [âš¡ Load Balancing Notes](#-load-balancing-notes)

---

# ğŸ¯ Aim of the Practical

This project helps you **understand how real industry deployments work**, including:

âœ” How a **web server** operates
âœ” How to configure **NGINX** for different environments
âœ” How a **dev server** differs from a **prod server**
âœ” How to set up **reverse proxies**, **virtual hosting**, **SSL**, **static file servers**, and **load balancing**

By going through each scenario, you will gain the confidence to build **robust production-grade deployments**.

---

# ğŸ“¦ Repository Structure

```
Deployment_Scenarios/
â”‚
â”œâ”€â”€ Scenario_1/
â”œâ”€â”€ Scenario_2/
â”œâ”€â”€ Scenario_3/
â”œâ”€â”€ Scenario_4/
â”œâ”€â”€ Scenario_5/
â”œâ”€â”€ Scenario_6/
â”œâ”€â”€ Scenario_7/
â”œâ”€â”€ Scenario_8/
â”œâ”€â”€ Scenario_9/
â”œâ”€â”€ Scenario_10/
â”œâ”€â”€ Scenario_11/
â”‚
â””â”€â”€ Detailed_Steps.docx   <-- Full documentation
```

Each scenario folder contains:

* Flask app
* Nginx configuration
* HTML templates
* Additional config files if required

---

# ğŸ§  Concepts You Will Learn

### ğŸ”¹ Development vs Production Servers

* How Flask dev server works
* Why dev servers should **never** be deployed
* How Waitress serves production traffic

### ğŸ”¹ NGINX as:

* Reverse Proxy
* Load Balancer
* Static asset server
* SSL / HTTPS termination proxy
* Virtual host manager (multiple domains on one or multiple apps)

### ğŸ”¹ Deployment Essentials

* Host-to-IP mapping on Windows (`C:/Windows/System32/drivers/etc/hosts`)
* Handling multiple apps on different ports
* Running apps on different systems
* Sticky sessions & ip_hash

---

# ğŸš€ Scenarios Overview

| Scenario | Description                                                      |
| -------- | ---------------------------------------------------------------- |
| **1**    | Basic Flask Dev Server                                           |
| **2**    | Production Server using Waitress                                 |
| **3**    | NGINX Reverse Proxy to a Single App                              |
| **4**    | NGINX + Waitress â€” Single App Handling Multiple Domains          |
| **5**    | NGINX with Multiple Server Blocks (two domains â†’ one app)        |
| **6**    | Two Separate Apps on Same Machine (different ports)              |
| **7**    | Two Apps Running on Different Machines                           |
| **8**    | HTTPS Setup with Self-Signed Certificate                         |
| **9**    | HTTPS with Real CA (Letâ€™s Encrypt / GoDaddy) *(not implemented)* |
| **10**   | Serving Static Files Efficiently                                 |
| **11**   | Load Balancing + Sticky Sessions                                 |

---

# âš™ï¸ Setup & Usage Instructions

## 1ï¸âƒ£ Running Application Servers

Open a terminal in your scenario folder and run:

```bash
python <app-file-name>.py
```

To run multiple apps simultaneously â†’ open multiple terminals.

---

## 2ï¸âƒ£ Running NGINX

Go to:

```
/nginx-1.26.3/
```

Start NGINX:

```bash
nginx.exe
```

Stop NGINX:

```bash
nginx -s stop     # Force stop
nginx -s quit     # Graceful stop
```

Reload configuration:

```bash
nginx -s reload
```

If NGINX refuses to stop:

```bash
taskkill /F /IM nginx.exe /T
```

---

## 3ï¸âƒ£ Editing NGINX Configurations

Edit:

```
/nginx-1.26.3/conf/nginx.conf
```

Each scenario folder includes the required configuration blocks.

---

# ğŸ“ Scenario Descriptions

Below is a **high-level summary** of each scenario. Full configurations are present inside each folder.

---

## **ğŸ”¥ Scenario 1 â€“ Basic Flask Dev Server**

* Runs using `app.run()`
* Debug mode enabled
* Auto reload
* Meant only for development

---

## **ğŸ”¥ Scenario 2 â€“ Production Server (Waitress)**

* Replace Flask dev server with **Waitress**
* Proper production WSGI server
* Accessible via system IP (`0.0.0.0`)

---

## **ğŸ”¥ Scenario 3 â€“ NGINX Reverse Proxy to One App**

* NGINX listens on port 80/1400
* Proxies requests to Waitress at `127.0.0.1:5001`
* No domain names yet (local development)

---

## **ğŸ”¥ Scenario 4 â€“ Virtual Hosting (One App, Multiple Domains)**

* Domains: `my_site_1.com`, `my_site_2.com`
* One app decides response based on `request.host`
* NGINX server block handles both domains
* Proxy pass â†’ `127.0.0.1:5005`

---

## **ğŸ”¥ Scenario 5 â€“ Two Server Blocks (Both Proxying to One App)**

* Each domain gets its own server block
* Same app receives both requests
* App identifies domain using `request.host`

---

## **ğŸ”¥ Scenario 6 â€“ Two Apps, Same Machine**

* App1 â†’ port 5000
* App2 â†’ port 5001
* NGINX routes based on domain name

---

## **ğŸ”¥ Scenario 7 â€“ Two Apps on Different Machines**

* NGINX routes traffic to different backend systems
* Realistic distributed deployment
* Example:

  * `my_site_1.com â†’ 10.53.163.247:5001`
  * `my_site_2.com â†’ 10.53.163.45:5000`

---

## **ğŸ”¥ Scenario 8 â€“ HTTPS with Self-Signed SSL**

* Generate certs using OpenSSL
* Use:

  ```
  ssl_certificate
  ssl_certificate_key
  ssl_protocols
  ssl_ciphers HIGH
  ```
* NGINX listens using SSL on port 1400

---

## **ğŸ”¥ Scenario 9 â€“ HTTPS with Real CA** *(Not Implemented)*

You can use:

* **Letâ€™s Encrypt (Free)**
* **GoDaddy / ZeroSSL / DigiCert (Paid)**

---

## **ğŸ”¥ Scenario 10 â€“ Static File Serving**

Use either:

```nginx
location /static/ {
    alias C:/path/to/static/;
}
```

or

```nginx
location /static/ {
    root C:/path/to/project/;
}
```

---

## **ğŸ”¥ Scenario 11 â€“ Load Balancing + Sticky Sessions**

NGINX upstream block:

```nginx
upstream my_waitress_servers {
    ip_hash;
    server 10.65.49.45:5000;
    server 10.65.49.154:5000;
    server 127.0.0.1:5000;
}
```

---

# ğŸ³ Commands Reference

### Kill all Nginx processes:

```bash
taskkill /F /IM nginx.exe /T
```

### Check IP of system:

```bash
ipconfig
```

### Reload NGINX after changes:

```bash
nginx -s reload
```

---

# ğŸ”’ SSL / HTTPS Notes

### With OpenSSL you can generate:

* Private key
* CSR (Certificate Signing Request)
* Self-signed certificate

Used in Scenario 8.

For production, use CA-signed certs (Letâ€™s Encrypt recommended).

---

# âš¡ Load Balancing Notes

NGINX supports:

* **Round robin** (default)
* **Least Connections**
* **ip_hash** (sticky sessions)

Used in Scenario 11 for session persistence.

---

**By Shrey Vyas**
MLOps | Deployment | Cloud | NGINX | DevOps Learner

